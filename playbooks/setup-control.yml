---
# Server Helper v1.0.0 - Control Node Setup Playbook
# ======================================================
# This playbook installs centralized monitoring services on the control node.
# These services monitor and manage ALL target servers from a single location.
#
# Services installed on control node:
#   - Uptime Kuma: Centralized uptime monitoring and alerting for all targets
#   - (Optional) Netdata Parent: Aggregate metrics from all target Netdata instances
#
# Usage:
#   ansible-playbook playbooks/setup-control.yml
#
# Prerequisites:
#   - Docker installed on control node
#   - Target nodes already configured with setup-targets.yml
#

- name: Server Helper - Control Node Setup
  hosts: localhost
  connection: local
  gather_facts: true

  vars_prompt:
    - name: confirm_control_setup
      prompt: "Install centralized monitoring services on this control node? (yes/no)"
      private: false
      default: "no"

  pre_tasks:
    - name: Verify setup confirmation
      ansible.builtin.fail:
        msg: "Setup cancelled by user"
      when: confirm_control_setup | lower != 'yes'

    - name: Display banner
      ansible.builtin.debug:
        msg:
          - "╔════════════════════════════════════════╗"
          - "║  Server Helper v1.0.0 - Ansible       ║"
          - "║  Control Node Setup                    ║"
          - "╚════════════════════════════════════════╝"

    - name: Detect OS
      ansible.builtin.fail:
        msg: "Control node setup requires Linux or macOS"
      when: ansible_os_family not in ['Debian', 'RedHat', 'Darwin']

    - name: Update apt cache (Debian/Ubuntu)
      ansible.builtin.apt:
        update_cache: true
        cache_valid_time: 3600
      become: true
      when: ansible_os_family == "Debian"

  tasks:
    # ==============================================
    # Install Docker on Control Node
    # ==============================================
    - name: Check if Docker is installed
      ansible.builtin.command: docker --version
      register: docker_check
      ignore_errors: true
      changed_when: false

    - name: Install Docker
      block:
        - name: Include Docker installation role
          ansible.builtin.include_role:
            name: geerlingguy.docker
          vars:
            docker_install_compose: true
            docker_users:
              - "{{ ansible_user_id }}"
      when: docker_check.rc != 0
      become: true

    - name: Ensure Docker is running
      ansible.builtin.systemd:
        name: docker
        state: started
        enabled: true
      become: true

    # ==============================================
    # Create Base Directory and Network
    # ==============================================
    - name: Create control node services directory
      ansible.builtin.file:
        path: "{{ control_node_install_dir }}"
        state: directory
        owner: "{{ ansible_user_id }}"
        group: "{{ ansible_user_id }}"
        mode: '0755'
      become: true

    - name: Create control-monitoring Docker network
      community.docker.docker_network:
        name: control-monitoring
        state: present

    # ==============================================
    # Install Centralized Uptime Kuma
    # ==============================================
    - name: Deploy centralized Uptime Kuma
      block:
        - name: Create Uptime Kuma directory
          ansible.builtin.file:
            path: "{{ control_node_install_dir }}/uptime-kuma"
            state: directory
            mode: '0755'

        - name: Create Uptime Kuma data directory
          ansible.builtin.file:
            path: "{{ control_node_install_dir }}/uptime-kuma/data"
            state: directory
            mode: '0755'

        - name: Deploy Uptime Kuma container
          community.docker.docker_container:
            name: uptime-kuma-control
            image: louislam/uptime-kuma:{{ control_uptime_kuma.version }}
            state: started
            restart_policy: unless-stopped
            ports:
              - "{{ control_uptime_kuma.port }}:3001"
            volumes:
              - "{{ control_node_install_dir }}/uptime-kuma/data:/app/data"
            labels:
              com.server-helper.service: "uptime-kuma-control"
              com.server-helper.type: "monitoring"

        - name: Wait for Uptime Kuma to be ready
          ansible.builtin.wait_for:
            host: localhost
            port: "{{ control_uptime_kuma.port }}"
            delay: 5
            timeout: 60

      when: control_uptime_kuma.enabled

    # ==============================================
    # Install Centralized Grafana
    # ==============================================
    - name: Deploy centralized Grafana
      block:
        - name: Create Grafana directory
          ansible.builtin.file:
            path: "{{ control_node_install_dir }}/grafana"
            state: directory
            mode: '0755'

        - name: Create Grafana data directory
          ansible.builtin.file:
            path: "{{ control_node_install_dir }}/grafana/data"
            state: directory
            owner: "472"
            group: "472"
            mode: '0755'

        - name: Create Grafana provisioning directories
          ansible.builtin.file:
            path: "{{ control_node_install_dir }}/grafana/provisioning/{{ item }}"
            state: directory
            mode: '0755'
          loop:
            - datasources
            - dashboards

        - name: Configure Grafana datasources
          ansible.builtin.copy:
            content: |
              apiVersion: 1
              datasources:
                - name: Loki
                  type: loki
                  access: proxy
                  url: http://loki-control:3100
                  isDefault: true
                  editable: false
                - name: Prometheus
                  type: prometheus
                  access: proxy
                  url: http://netdata-parent:19999/api/v1/allmetrics?format=prometheus
                  editable: false
            dest: "{{ control_node_install_dir }}/grafana/provisioning/datasources/datasources.yml"
            mode: '0644'

        - name: Deploy Grafana container
          community.docker.docker_container:
            name: grafana-control
            image: grafana/grafana:{{ control_grafana.version }}
            state: started
            restart_policy: unless-stopped
            ports:
              - "{{ control_grafana.port }}:3000"
            volumes:
              - "{{ control_node_install_dir }}/grafana/data:/var/lib/grafana"
              - "{{ control_node_install_dir }}/grafana/provisioning:/etc/grafana/provisioning"
            env:
              GF_SECURITY_ADMIN_USER: "{{ control_grafana.admin_user }}"
              GF_SECURITY_ADMIN_PASSWORD: "{{ vault_control_grafana_password | default('admin') }}"
              GF_INSTALL_PLUGINS: "{{ control_grafana.plugins }}"
            networks:
              - name: control-monitoring
            labels:
              com.server-helper.service: "grafana-control"
              com.server-helper.type: "monitoring"

        - name: Wait for Grafana to be ready
          ansible.builtin.wait_for:
            host: localhost
            port: "{{ control_grafana.port }}"
            delay: 5
            timeout: 60

      when: control_grafana.enabled

    # ==============================================
    # Install Centralized Loki
    # ==============================================
    - name: Deploy centralized Loki
      block:
        - name: Create Loki directory
          ansible.builtin.file:
            path: "{{ control_node_install_dir }}/loki"
            state: directory
            mode: '0755'

        - name: Create Loki data directory
          ansible.builtin.file:
            path: "{{ control_node_install_dir }}/loki/data"
            state: directory
            owner: "10001"
            group: "10001"
            mode: '0755'

        - name: Create Loki configuration
          ansible.builtin.copy:
            content: |
              auth_enabled: false

              server:
                http_listen_port: 3100
                grpc_listen_port: 9096

              common:
                instance_addr: 127.0.0.1
                path_prefix: /loki
                storage:
                  filesystem:
                    chunks_directory: /loki/chunks
                    rules_directory: /loki/rules
                replication_factor: 1
                ring:
                  kvstore:
                    store: inmemory

              query_range:
                results_cache:
                  cache:
                    embedded_cache:
                      enabled: true
                      max_size_mb: 100

              schema_config:
                configs:
                  - from: 2020-10-24
                    store: tsdb
                    object_store: filesystem
                    schema: v13
                    index:
                      prefix: index_
                      period: 24h

              ruler:
                alertmanager_url: http://localhost:9093

              limits_config:
                retention_period: {{ control_loki.retention_period }}
                allow_structured_metadata: true
                volume_enabled: true

              compactor:
                working_directory: /loki/compactor
                compaction_interval: 10m
                retention_enabled: true
                retention_delete_delay: 2h
                delete_request_store: filesystem
            dest: "{{ control_node_install_dir }}/loki/loki-config.yml"
            mode: '0644'

        - name: Deploy Loki container
          community.docker.docker_container:
            name: loki-control
            image: grafana/loki:{{ control_loki.version }}
            state: started
            restart_policy: unless-stopped
            command: -config.file=/etc/loki/loki-config.yml
            ports:
              - "{{ control_loki.port }}:3100"
            volumes:
              - "{{ control_node_install_dir }}/loki/loki-config.yml:/etc/loki/loki-config.yml:ro"
              - "{{ control_node_install_dir }}/loki/data:/loki"
            networks:
              - name: control-monitoring
            labels:
              com.server-helper.service: "loki-control"
              com.server-helper.type: "logging"

        - name: Wait for Loki to be ready
          ansible.builtin.wait_for:
            host: localhost
            port: "{{ control_loki.port }}"
            delay: 5
            timeout: 60

      when: control_loki.enabled

    # ==============================================
    # Install Netdata Parent (Centralized Metrics)
    # ==============================================
    - name: Deploy Netdata Parent
      block:
        - name: Create Netdata directory
          ansible.builtin.file:
            path: "{{ control_node_install_dir }}/netdata"
            state: directory
            mode: '0755'

        - name: Create Netdata config directory
          ansible.builtin.file:
            path: "{{ control_node_install_dir }}/netdata/config"
            state: directory
            mode: '0755'

        - name: Create Netdata data directory
          ansible.builtin.file:
            path: "{{ control_node_install_dir }}/netdata/data"
            state: directory
            mode: '0755'

        - name: Create Netdata stream.conf for parent mode
          ansible.builtin.copy:
            content: |
              # Netdata Parent Configuration
              # This accepts streams from child Netdata instances

              [{{ control_netdata.stream_api_key }}]
                  # Accept connections from children with this API key
                  enabled = yes

                  # Allow from any IP (restrict in production)
                  allow from = *

                  # Store metrics from children in memory
                  default history = 3600

                  # Memory mode for child data
                  default memory mode = dbengine

                  # Health checks for streamed metrics
                  health enabled by default = auto

                  # Allow children to be proxied to Netdata Cloud
                  default postpone alarms on connect seconds = 60

              # Require API key for all incoming streams
              [stream]
                  enabled = yes
                  enable sending = no
                  enable replication = yes
            dest: "{{ control_node_install_dir }}/netdata/config/stream.conf"
            mode: '0644'

        - name: Create Netdata netdata.conf for parent mode
          ansible.builtin.copy:
            content: |
              # Netdata Parent Configuration
              [global]
                  hostname = netdata-parent
                  history = 7200
                  memory mode = dbengine

              [web]
                  bind to = *

              [db]
                  mode = dbengine
                  dbengine multihost disk space MB = 2048
                  dbengine page cache size MB = 64

              [health]
                  enabled = yes
            dest: "{{ control_node_install_dir }}/netdata/config/netdata.conf"
            mode: '0644'

        - name: Deploy Netdata Parent container
          community.docker.docker_container:
            name: netdata-parent
            image: netdata/netdata:{{ control_netdata.version }}
            state: started
            restart_policy: unless-stopped
            ports:
              - "{{ control_netdata.port }}:19999"
            volumes:
              - "{{ control_node_install_dir }}/netdata/config/netdata.conf:/etc/netdata/netdata.conf:ro"
              - "{{ control_node_install_dir }}/netdata/config/stream.conf:/etc/netdata/stream.conf:ro"
              - "{{ control_node_install_dir }}/netdata/data:/var/lib/netdata"
              - "/etc/passwd:/host/etc/passwd:ro"
              - "/etc/group:/host/etc/group:ro"
              - "/etc/localtime:/etc/localtime:ro"
              - "/proc:/host/proc:ro"
              - "/sys:/host/sys:ro"
            capabilities:
              - SYS_PTRACE
              - SYS_ADMIN
            security_opts:
              - apparmor:unconfined
            networks:
              - name: control-monitoring
            labels:
              com.server-helper.service: "netdata-parent"
              com.server-helper.type: "monitoring"

        - name: Wait for Netdata Parent to be ready
          ansible.builtin.wait_for:
            host: localhost
            port: "{{ control_netdata.port }}"
            delay: 5
            timeout: 60

      when: control_netdata.enabled

    # ==============================================
    # Install Scanopy (Container Security Scanning)
    # ==============================================
    - name: Deploy Scanopy
      block:
        - name: Create Scanopy directory
          ansible.builtin.file:
            path: "{{ control_node_install_dir }}/scanopy"
            state: directory
            mode: '0755'

        - name: Deploy Scanopy container
          community.docker.docker_container:
            name: scanopy-control
            image: aquasec/trivy:{{ control_scanopy.trivy_version }}
            state: started
            restart_policy: unless-stopped
            command: server --listen 0.0.0.0:{{ control_scanopy.port }}
            ports:
              - "{{ control_scanopy.port }}:8080"
            volumes:
              - "/var/run/docker.sock:/var/run/docker.sock:ro"
              - "{{ control_node_install_dir }}/scanopy/cache:/root/.cache"
            labels:
              com.server-helper.service: "scanopy-control"
              com.server-helper.type: "security"

        - name: Wait for Scanopy to be ready
          ansible.builtin.wait_for:
            host: localhost
            port: "{{ control_scanopy.port }}"
            delay: 5
            timeout: 60

      when: control_scanopy.enabled

    # ==============================================
    # Install PruneMate (Docker Cleanup Automation)
    # ==============================================
    - name: Deploy PruneMate
      block:
        - name: Create PruneMate directory
          ansible.builtin.file:
            path: "{{ control_node_install_dir }}/prunemate"
            state: directory
            mode: '0755'

        - name: Create PruneMate configuration
          ansible.builtin.copy:
            content: |
              # PruneMate Configuration
              # Cleanup schedule and rules

              # Images
              PRUNE_IMAGES_ENABLED=true
              PRUNE_IMAGES_FILTER="until=720h"  # 30 days
              PRUNE_IMAGES_DANGLING=true

              # Containers
              PRUNE_CONTAINERS_ENABLED=true
              PRUNE_CONTAINERS_FILTER="until=168h"  # 7 days

              # Volumes
              PRUNE_VOLUMES_ENABLED=true
              PRUNE_VOLUMES_FILTER="all"

              # Networks
              PRUNE_NETWORKS_ENABLED=true

              # Build cache
              PRUNE_BUILD_CACHE_ENABLED=true
              PRUNE_BUILD_CACHE_FILTER="until=168h"  # 7 days

              # Schedule (cron format)
              SCHEDULE="{{ control_prunemate.schedule }}"  # Weekly Sunday 3 AM
            dest: "{{ control_node_install_dir }}/prunemate/config.env"
            mode: '0644'

        - name: Deploy PruneMate container
          community.docker.docker_container:
            name: prunemate-control
            image: alpine:latest
            state: started
            restart_policy: unless-stopped
            command: >
              sh -c "
              apk add --no-cache docker-cli dcron &&
              echo '{{ control_prunemate.schedule }} docker system prune -af --filter until=720h' > /etc/crontabs/root &&
              crond -f -l 2
              "
            volumes:
              - "/var/run/docker.sock:/var/run/docker.sock"
            labels:
              com.server-helper.service: "prunemate-control"
              com.server-helper.type: "maintenance"

      when: control_prunemate.enabled

    # ==============================================
    # Create Monitoring Configuration Template
    # ==============================================
    - name: Create monitoring targets template
      ansible.builtin.template:
        src: templates/control-monitoring-targets.yml.j2
        dest: "{{ control_node_install_dir }}/monitoring-targets.yml"
        mode: '0644'
      vars:
        target_servers: "{{ groups['all'] | default([]) }}"
      when: control_uptime_kuma.enabled
      ignore_errors: true

  post_tasks:
    - name: Display completion message
      ansible.builtin.debug:
        msg:
          - "═══════════════════════════════════════"
          - "      Control Node Setup Complete!"
          - "═══════════════════════════════════════"
          - ""
          - "Centralized Services:"
          - "{% if control_uptime_kuma.enabled %}"
          - "  ✓ Uptime Kuma: http://{{ ansible_default_ipv4.address }}:{{ control_uptime_kuma.port }}"
          - "{% endif %}"
          - "{% if control_grafana.enabled %}"
          - "  ✓ Grafana: http://{{ ansible_default_ipv4.address }}:{{ control_grafana.port }}"
          - "{% endif %}"
          - "{% if control_loki.enabled %}"
          - "  ✓ Loki: http://{{ ansible_default_ipv4.address }}:{{ control_loki.port }}"
          - "{% endif %}"
          - "{% if control_netdata.enabled %}"
          - "  ✓ Netdata Parent: http://{{ ansible_default_ipv4.address }}:{{ control_netdata.port }}"
          - "{% endif %}"
          - "{% if control_scanopy.enabled %}"
          - "  ✓ Scanopy (Trivy): http://{{ ansible_default_ipv4.address }}:{{ control_scanopy.port }}"
          - "{% endif %}"
          - "{% if control_prunemate.enabled %}"
          - "  ✓ PruneMate: Automated Docker cleanup (cron: {{ control_prunemate.schedule }})"
          - "{% endif %}"
          - ""
          - "Next steps:"
          - "  1. Access Grafana (admin/admin) and change the password"
          - "  2. Access Uptime Kuma and complete initial setup"
          - "  3. Configure monitors for all target servers"
          - "  4. Setup notification endpoints (email, Discord, Telegram, etc.)"
          - "  5. Configure target nodes to stream to this control node:"
          - "     - Set control_node_ip in group_vars/all.yml"
          - "     - Set target_promtail.send_to_central: true"
          - "     - Set target_netdata.stream_to_parent: true"
          - ""
          - "Monitor your target servers:"
          - "{% for host in groups['all'] | default([]) %}"
          - "  - {{ host }}: {{ hostvars[host]['ansible_host'] | default(host) }}"
          - "{% endfor %}"
          - ""
          - "Netdata Streaming:"
          - "  API Key for child nodes: {{ control_netdata.stream_api_key }}"
          - "  Parent address: {{ ansible_default_ipv4.address }}:{{ control_netdata.port }}"
          - ""
          - "Loki Log Aggregation:"
          - "  Push URL for Promtail: http://{{ ansible_default_ipv4.address }}:{{ control_loki.port }}/loki/api/v1/push"
          - ""

    - name: Save control node service URLs
      ansible.builtin.copy:
        content: |
          # Server Helper - Control Node Services
          # Generated: {{ ansible_date_time.iso8601 }}

          ════════════════════════════════════════════
          CENTRALIZED MONITORING SERVICES
          ════════════════════════════════════════════

          {% if control_grafana.enabled %}
          Grafana (Dashboards): http://{{ ansible_default_ipv4.address }}:{{ control_grafana.port }}
            - Default credentials: admin / admin (change on first login)
            - Pre-configured datasources: Loki, Netdata
          {% endif %}

          {% if control_loki.enabled %}
          Loki (Log Aggregation): http://{{ ansible_default_ipv4.address }}:{{ control_loki.port }}
            - Push URL for Promtail: http://{{ ansible_default_ipv4.address }}:{{ control_loki.port }}/loki/api/v1/push
            - Retention: {{ control_loki.retention_period }}
          {% endif %}

          {% if control_netdata.enabled %}
          Netdata Parent (Metrics): http://{{ ansible_default_ipv4.address }}:{{ control_netdata.port }}
            - Stream API Key: {{ control_netdata.stream_api_key }}
            - Child nodes stream to: {{ ansible_default_ipv4.address }}:{{ control_netdata.port }}
          {% endif %}

          {% if control_uptime_kuma.enabled %}
          Uptime Kuma (Uptime Monitoring): http://{{ ansible_default_ipv4.address }}:{{ control_uptime_kuma.port }}
          {% endif %}

          {% if control_scanopy.enabled %}
          Scanopy/Trivy (Security Scanner): http://{{ ansible_default_ipv4.address }}:{{ control_scanopy.port }}
          {% endif %}

          {% if control_prunemate.enabled %}
          PruneMate (Docker Cleanup): Automated (Schedule: {{ control_prunemate.schedule }})
          {% endif %}

          ════════════════════════════════════════════
          TARGET NODE CONFIGURATION
          ════════════════════════════════════════════

          To stream data from target nodes to this control node:

          1. Edit group_vars/all.yml on your control node:

             control_node_ip: "{{ ansible_default_ipv4.address }}"

             target_promtail:
               send_to_central: true

             target_netdata:
               stream_to_parent: true

          2. Re-run setup on target nodes:
             ansible-playbook playbooks/setup-targets.yml

          Target Servers Configured:
          {% for host in groups['all'] | default([]) %}
          - {{ host }}: {{ hostvars[host]['ansible_host'] | default(host) }}
          {% endfor %}

          ════════════════════════════════════════════
          USAGE EXAMPLES
          ════════════════════════════════════════════

          # View all logs in Grafana
          Open http://{{ ansible_default_ipv4.address }}:{{ control_grafana.port }}
          Navigate to Explore > Select Loki datasource

          # View all server metrics
          Open http://{{ ansible_default_ipv4.address }}:{{ control_netdata.port }}
          Child nodes appear in the node selector dropdown

          # Scan container with Scanopy/Trivy
          docker run --rm -v /var/run/docker.sock:/var/run/docker.sock \
            aquasec/trivy client --remote http://localhost:{{ control_scanopy.port }} IMAGE_NAME

          # View container logs
          docker logs grafana-control
          docker logs loki-control
          docker logs netdata-parent
        dest: "{{ control_node_install_dir }}/service_urls.txt"
        mode: '0644'
